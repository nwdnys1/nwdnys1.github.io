---
title: 《应用系统体系结构》课程笔记
date: 2024-09-23 14:01:00
categories: 课程笔记
tags:
  - 架构
  - 后端
index_img:
banner_img:
excerpt: " "
---

## 预备知识：如何用 Docker 快速部署本地环境？

这门课程将会学习很多技术栈 同时也就势必需要配置很多环境 如果还像以前一样 前端用 npm 手动启动 后端用 IDEA 启动 数据库作为自启动服务 那么后续要装的环境只会越来越多 越来越难管理 不说系统盘会不会爆炸 启动一次完整的项目可能都要花半天 因此使用 Docker 来配置本地的环境 做到一键启动

### 从前端 Vite 项目开始

- 和服务器上的部署都类似 不过我们通常本地的操作系统都是 Windows 官方推荐安装一个图形化前端 Docker Desktop 链接放这里：https://docs.docker.com/desktop/install/windows-install/ 安装完后需要配置虚拟环境 网上文档里都有教学 我就不赘述了 本人是使用了 HyperV

- 还是编写 Dockerfile 和服务器上的部署不同 为了追求本地开发的效率 我们不能再通过先编译生成静态文件复制到容器内部来部署了 这样子部署 开发时无法热重载 代码更改看不到效果

  考虑到本地开发 源代码都是在的 不妨利用挂载来进行热重载 因此采用下面的 Dockerfile：

  ```
  FROM node:18-alpine

  WORKDIR /frontend

  # 只设置启动命令
  CMD ["npm", "start", "--", "--host"]
  ```

  也就是和本地一样直接启动 `--host`参数是用于暴露端口的 不设置的话宿主机无法访问这个端口

- 然后编写一下 docker-compose 文件 和服务器上部署区别不大 加上一个挂载即可

```
  frontend:
    image: ebook-frontend
    container_name: ebook-frontend
    ports:
      - 5173:5173
    networks:
      - my-network
    volumes:
      - ../frontend:/frontend
    command: sh -c "npm install" # 这条命令初次运行需要加上 因为linux环境有些依赖可能需要重新安装 之后就可以注释掉了 因为挂载实现了持久化 后续再有缺少依赖就重新加上
```

- 最后可以用命令行一键拉起 后续也可以在 Docker Desktop 里使用 GUI 来启动 里面还提供了终端、日志、浏览文件等功能 很方便

### 后端 Spring Boot

- 后端的思路是一样的 也是挂载后直接运行即可 注意 maven 的本地依赖也要挂载 要不然每次都需要重新下载 下面贴一下代码
  Dockerfile:

  ```
  FROM maven:3.8-openjdk-17

  WORKDIR /backend

  CMD ["mvn", "spring-boot:run"]

  EXPOSE 8080
  ```

  docker-compose.yml:

  ```
  backend:
  image: ebook-backend
  container_name: ebook-backend
  ports:
    - 8080:8080
  networks:
    - my-network
  volumes:
    - ../backend:/backend
    - E:/.m2/repository:/root/.m2/repository #挂载本地仓库
  env_file:
    - ../deployment/backend/.env
  ```

- ps：本人测试后发现容器内编译+启动大概需要十几秒 而 IDEA 启动却只需要 3-4 秒 不知道这其中的差别在哪 因此还是采用 IDEA 来启动项目

### MySQL 数据库

- 和服务器上部署无区别 另外提一嘴 既然服务器上已经部署了数据库了 其实就无需再在本地配置数据库容器了 直接连服务器方便又省心 Redis 也是同理的

## 9.23

### 谈谈应用架构

- 应用服务器首先为了安全考虑（比如数据库的端口不能暴露） 可以把应用和**数据库**、**文件服务器**等分开部署 通过内网访问 防止外网攻击

- 随后可以添加**分布式缓存服务器** 利用服务器的内存来增加读取速度 考虑到缓存需要少写 设计数据库时就可以把一张表拆分为只读数据和多写数据

- 请求一多 就需要**负载均衡服务器**来进行转发 比如 nginx 有一些新的问题就需要解决 比如分布式 session 的处理

- 数据一多 数据库就需要分布式部署 利用**主从复制**就可以做读的负载均衡 以及容灾备份 为了充分利用资源 可以轮流设为主节点 防止从节点过冷 为了保证主节点的可用性 还需要哨兵等中间件

- 图片音频一多 就需要 **CDN 服务器**来进行内容分发 为了单一访问 还需要一个反向代理服务器来代理这些 CDN 服务器

- 为了代码简单 可以把缓存、数据库、文件服务器的操作统一抽象成一个 API 形成**统一数据访问网关**

- 出现 NoSQL 数据库和搜索引擎后 数据访问的逻辑会更复杂 继续在网关里统一编写

- 为了处理异步通信 需要**消息服务器**

- 不同的应用服务器也可以提取出公共的服务 形成**微服务架构** 等待应用调用

### 服务的有状态和无状态

- http 协议是无状态的协议 即没有办法记住用户的状态

  有状态的服务是需要占用资源的 比如把实例放在内存里 但是不能无限扩大 如果要限制资源大小 又会因为 LRU 等策略导致缓冲池的抖动

  因此 要尽量使用无状态的服务 保留必需的有状态实例

- Spring Bean 的作用域（以一个 service 为例）

  - singleton：全局单例（默认）
  - prototype：每调用一次就创建一个新的实例
  - request：每进行一次 http 请求就创建一个
  - session：一次会话创建一个实例
  - application：一个 ServletContext 生命周期创建一个实例
  - websocket：一次 websocket 对话创建一个实例

- 数据库连接池=核心数\*2+有效硬盘数 与用户数无关
  ![](https://image.blog.nwdnysl.site/image-e386b0b13719a1472c0f8d15c2f006a4.png)

### 作业：会话计时器

![](https://image.blog.nwdnysl.site/20240925165306-d3f7c51e9b6c2b6c2526349dcb31357e.png)

- 首先为了作业要求 我需要把原本使用 Spring Security 默认的登录校验流程提取到自定义的 LoginController 里 研究了一下午后 总结流程为：在自定义的 Login 函数里 调用默认的 authenticate 函数进行登录校验 可以是外部注入的（那么就是自定义校验逻辑） 也可以使用默认的（使用 daoAuthenticationProvider 类）把用户信息放到 SecurityContextHolder 里 再把这个上下文里的数据放入 session 然后清除上下文 实际上后续任何需要验证的请求 都会遵循这三步（查找 session 放入上下文 在请求处理过程中使用上下文 清空上下文）

  至于 logout 函数就是失效一下 session 即可

- 然后我们创建 TimerService 来计时 实现很简单 详见 Ebook 仓库代码

- 问题的解答：
  在 Controller 和 Service 层都使用了 session 作用域的 scope。
  - Service 层使用 session 的原因：
    - 用户会话保持的时间是一个状态 需要有状态的服务 使用默认的单例的话 每个用户获取到的 service 都是同一个实例 无法为每一个用户维护不同的状态 所以显然不用单例模式 同理的 如果选用 prototype 同一个用户每一次调用会获取到不同的服务 每次都会获得一个新的计时器 自然也不符合要求
    - 而既然要求一个会话维护一个状态 那么 session 作用域是最好的选择 即一个用户如果有新的会话 调用的 service 就会新创建一个实例 做到一次会话对应一个计时器对应一个状态 实现为每一次会话记录持续时间
  - Controller 层使用 session 的原因：
    - 如果服务层使用了 session 作用域 而控制层却使用单例作用域 因为控制层只被创造一次 也就只进行一次依赖注入 也就是说控制层实际上只会调用同一个服务层实例 那么服务层的 session 作用域也就无效了 同理如果是 prototype 作用域 会出现多个 controller 实例注入了同一个服务层实例的问题 而且也没必要每次请求都创建新的控制层实例 所以也不妥
    - 和服务层一样使用 session 作用域是最好的选择 同一个会话的所有请求对应控制层 这个控制层又会对应注入一个服务层

## 9.25

### 异步通信模型

- 为什么需要异步模型（而不用同步模型）：

  1. 上层和接口还是紧耦合的
  2. 缺少调用保障
  3. 软件声明
  4. 没有请求的 buffer
  5. 过于强调请求响应模型
  6. 交流是不可靠的
  7. 通俗理解：同步模型下如果有超过服务器处理能力的高并发请求 所有超过阈值的请求都会被抛弃 而异步模型就可以塞入消息队列慢慢处理 直接响应用户 告知请求一定会被处理

     如果请求数始终超过服务器能力 那么同步异步没有区别 都无法处理 只能提升资源

- 什么是异步模型：没有服务端和客户端之分 而是用消息中间件来处理异步信息 就好比你给室友发条 wx 叫他买早饭 你只需要发送出消息 不需要等待响应而阻塞 也不需要知道室友买早饭的过程

- kafka 中有生产者和消费者 生产者（比如控制层）把消息放入类似缓冲区的 topic 区中 等待消费者（比如服务层）取出进行处理

- 客户端如何知道异步处理的结果？

  1. ajax 重新发一个请求确认
  2. websocket 推送
  3. 消费者完成任务后 把结果放入 topic 等待原来的生产者取出进行处理

- java 提供一个 JMS 来进行消息处理 是异步且可靠的（一定会保障消息传输到）

- JMS 消息的格式：

  1. 一个消息头
     - 发送目标
     - 发送模式
     - 消息 ID
     - 发送时间戳
     - 相关消息 ID
     - 回复给谁
     - 有无转发
     - 消息类型
     - 过期时间
     - 优先级
  2. 消息属性（可选 可以作为消息头的自定义扩展）
     - 用户 ID
     - AppID
     - 转发数
     - 组 ID
     - 生产者和消费者的事务 ID
     - 接受的时间戳
     - 消息状态
  3. 消息体（可选）
     - Text：一个 String 对象
     - Map：一个键值对集合
     - Bytes：一个字节数组
     - Stream：一个流对象
     - Object：一个可序列化的对象
     - Message：上述五个消息类的父类

- 如何实现（JMS）

  1. 消息发布有两种类型 点对点和广播 一个通过 queue 一个通过 topic
  2. 向连接工厂获取一个连接 创建一个上下文和 JMS 服务器进行交互
  3. 通过上下文创建消息 进行发送和接受 发送时可以设置上述的 selector 接收异步的消息则需要创建一个 listener 来进行监听 在 onMessage 函数里编写处理操作
  4. 持久化订阅：创建一个持久化的消费者 订阅一个 topic 会把
     所有未过期且未收到的消息接收
  5. 消息浏览器：只浏览消息 不消费
  6. 对于下订单 也就是控制层向某一个 topic 发送订单信息 服务层监听这个 topic 并消费每个订单消息

### Apache Kafka

- kafka 基于日志来存储消息 是只追加的数据 即使用时间戳来标记删除和更新 写的操作速度快

- 由于 topic 的消息是在内存中存储的 每个用户会维护一个目前读到的消息在内存中的偏移量 来保证每个用户读消息不会乱

- topic 很大时可以用哈希分区 甚至可以形成集群 部署到不同服务器上 为了容灾还可以加复制因子参数 来进行备份

### 作业：使用 Kafka 中间件处理订单请求

- 配置 kafka 环境：使用容器即可 新版 kafka 无需再使用 zookeeper 只需要使用内置的 raft 即可 总共两行代码搞定 `docker pull apache/kafka:3.7.0` `docker run -d -p 9092:9092 apache/kafka:3.7.0`
- 在 Spring 里使用 kafka(可参考：https://blog.csdn.net/Eternal_Blue/article/details/125293622)
  1. 首先添加依赖`spring-kafka` 然后在 application.yml 文件里配置 bootstrap-servers（服务 url）
  2. 创建话题：随便创建个类 或者在启动类里 注册类型为 NewTopic 的 Bean spring 会自动读取并在 kafka 里进行创建 参数分别是 topic 名称、分区数和复制因子
  3. 发送消息：以下订单为例 在控制层先进行鉴权获取 uid（因为消息接受时上下文就没有了） 然后调用 kafkaTemplate 的 send 方法发送封装好的消息即可
  4. 监听消息：创建一个 Listener 类 在里面编写函数并打上`@KafkaListener`注解 这个函数会创建一个消费者实例进行消息的监听 注解参数有很多 主要是 topic 名称和 groupId 我的理解 一个组就是多个消费者并发的消费队列中的消息 可以提高效率 如果消息只有 1 个 那就会随机发给组内某一个消费者
  5. 完成操作：消费者接收到下订单的消息后 调用服务层的方法来处理订单 把订单处理的结果使用 websocket 进行推送 即可让用户知道结果了

## 9.30

### WebSocket

- ws 是一个全双工的应用协议 即双向工作对等 底层是TCP协议

- ws应用会运行一个endpoint 注册此endpoint的uri作为连接端点 
- 连接建立包含两部分 握手和数据传输 使用GET向endpoint进行请求 会进行协议的升级 握手后协议升级为ws 

- 使用注解@ServerEndpoint来注册一个endpoint 作为服务端 OnOpen函数中进行连接建立时的操作 OnMessage函数进行收到消息时的操作 OnError、OnClose同理

- 群发消息如果使用遍历是很慢的 因此需要把sessionMap开成并发安全结构 后续可以多线程处理

- ws支持自定义编码器 对于文本和二进制消息有两个接口 实现接口中的encode方法后即可自定义如何编码 同样也有解码器接口 

- 通过编写Message类的子类 可以实现多种自定义消息类 在decode时就可以根据类别对应处理 多个endpoint就可以使用一个decoder （也就是说 比如一个聊天室的endpoint 一个点赞消息通知的endpoint 聊天室可以有两种消息Text和Image 点赞可以有一种消息LikeM 三种消息都编码成文本 在同一个decoder里解码 分别解成三种子消息 然后根据消息类型分别处理）

- 对于下订单服务 当listener收到订单处理完成的消息时 应该把消息封装后通过注入的ws发送给对应用户 用户在前端需要先注册好ws服务 可以再下订单之前建立连接 收到ws消息后关闭连接

- 总结
  - ajax实现的是前端的异步处理 即用户点击发送请求后可以立即进行其他操作 收到响应后会自动处理
  - 消息队列实现的是后端的异步处理 让服务的处理可以异步实现 由于异步无法使用响应让用户知道结果 就使用ws来实时通知用户
