---
title: 《应用系统体系结构》课程笔记
date: 2024-09-23 14:01:00
categories: 课程笔记
tags:
  - 架构
  - 后端
index_img:
banner_img:
excerpt: " "
---

## 预备知识：如何用 Docker 快速部署本地环境？

这门课程将会学习很多技术栈 同时也就势必需要配置很多环境 如果还像以前一样 前端用 npm 手动启动 后端用 IDEA 启动 数据库作为自启动服务 那么后续要装的环境只会越来越多 越来越难管理 不说系统盘会不会爆炸 启动一次完整的项目可能都要花半天 因此使用 Docker 来配置本地的环境 做到一键启动

### 从前端 Vite 项目开始

- 和服务器上的部署都类似 不过我们通常本地的操作系统都是 Windows 官方推荐安装一个图形化前端 Docker Desktop 链接放这里：https://docs.docker.com/desktop/install/windows-install/ 安装完后需要配置虚拟环境 网上文档里都有教学 我就不赘述了 本人是使用了 HyperV

- 还是编写 Dockerfile 和服务器上的部署不同 为了追求本地开发的效率 我们不能再通过先编译生成静态文件复制到容器内部来部署了 这样子部署 开发时无法热重载 代码更改看不到效果

  考虑到本地开发 源代码都是在的 不妨利用挂载来进行热重载 因此采用下面的 Dockerfile：

  ```
  FROM node:18-alpine

  WORKDIR /frontend

  # 只设置启动命令
  CMD ["npm", "start", "--", "--host"]
  ```

  也就是和本地一样直接启动 `--host`参数是用于暴露端口的 不设置的话宿主机无法访问这个端口

- 然后编写一下 docker-compose 文件 和服务器上部署区别不大 加上一个挂载即可

```
  frontend:
    image: ebook-frontend
    container_name: ebook-frontend
    ports:
      - 5173:5173
    networks:
      - my-network
    volumes:
      - ../frontend:/frontend
    command: sh -c "npm install" # 这条命令初次运行需要加上 因为linux环境有些依赖可能需要重新安装 之后就可以注释掉了 因为挂载实现了持久化 后续再有缺少依赖就重新加上
```

- 最后可以用命令行一键拉起 后续也可以在 Docker Desktop 里使用 GUI 来启动 里面还提供了终端、日志、浏览文件等功能 很方便

### 后端 Spring Boot

- 后端的思路是一样的 也是挂载后直接运行即可 注意 maven 的本地依赖也要挂载 要不然每次都需要重新下载 下面贴一下代码
  Dockerfile:

  ```
  FROM maven:3.8-openjdk-17

  WORKDIR /backend

  CMD ["mvn", "spring-boot:run"]

  EXPOSE 8080
  ```

  docker-compose.yml:

  ```
  backend:
  image: ebook-backend
  container_name: ebook-backend
  ports:
    - 8080:8080
  networks:
    - my-network
  volumes:
    - ../backend:/backend
    - E:/.m2/repository:/root/.m2/repository #挂载本地仓库
  env_file:
    - ../deployment/backend/.env
  ```

- ps：本人测试后发现容器内编译+启动大概需要十几秒 而 IDEA 启动却只需要 3-4 秒 不知道这其中的差别在哪 因此还是采用 IDEA 来启动项目

### MySQL 数据库

- 和服务器上部署无区别 另外提一嘴 既然服务器上已经部署了数据库了 其实就无需再在本地配置数据库容器了 直接连服务器方便又省心 Redis 也是同理的

## 9.23

### 谈谈应用架构

- 应用服务器首先为了安全考虑（比如数据库的端口不能暴露） 可以把应用和**数据库**、**文件服务器**等分开部署 通过内网访问 防止外网攻击

- 随后可以添加**分布式缓存服务器** 利用服务器的内存来增加读取速度 考虑到缓存需要少写 设计数据库时就可以把一张表拆分为只读数据和多写数据

- 请求一多 就需要**负载均衡服务器**来进行转发 比如 nginx 有一些新的问题就需要解决 比如分布式 session 的处理

- 数据一多 数据库就需要分布式部署 利用**主从复制**就可以做读的负载均衡 以及容灾备份 为了充分利用资源 可以轮流设为主节点 防止从节点过冷 为了保证主节点的可用性 还需要哨兵等中间件

- 图片音频一多 就需要 **CDN 服务器**来进行内容分发 为了单一访问 还需要一个反向代理服务器来代理这些 CDN 服务器

- 为了代码简单 可以把缓存、数据库、文件服务器的操作统一抽象成一个 API 形成**统一数据访问网关**

- 出现 NoSQL 数据库和搜索引擎后 数据访问的逻辑会更复杂 继续在网关里统一编写

- 为了处理异步通信 需要**消息服务器**

- 不同的应用服务器也可以提取出公共的服务 形成**微服务架构** 等待应用调用

### 服务的有状态和无状态

- http 协议是无状态的协议 即没有办法记住用户的状态

  有状态的服务是需要占用资源的 比如把实例放在内存里 但是不能无限扩大 如果要限制资源大小 又会因为 LRU 等策略导致缓冲池的抖动

  因此 要尽量使用无状态的服务 保留必需的有状态实例

- Spring Bean 的作用域（以一个 service 为例）

  - singleton：全局单例（默认）
  - prototype：每调用一次就创建一个新的实例
  - request：每进行一次 http 请求就创建一个
  - session：一次会话创建一个实例
  - application：一个 ServletContext 生命周期创建一个实例
  - websocket：一次 websocket 对话创建一个实例

- 数据库连接池=核心数\*2+有效硬盘数 与用户数无关
  ![](https://image.blog.nwdnysl.site/image-e386b0b13719a1472c0f8d15c2f006a4.png)

### 作业：会话计时器

![](https://image.blog.nwdnysl.site/20240925165306-d3f7c51e9b6c2b6c2526349dcb31357e.png)

- 首先为了作业要求 我需要把原本使用 Spring Security 默认的登录校验流程提取到自定义的 LoginController 里 研究了一下午后 总结流程为：在自定义的 Login 函数里 调用默认的 authenticate 函数进行登录校验 可以是外部注入的（那么就是自定义校验逻辑） 也可以使用默认的（使用 daoAuthenticationProvider 类）把用户信息放到 SecurityContextHolder 里 再把这个上下文里的数据放入 session 然后清除上下文 实际上后续任何需要验证的请求 都会遵循这三步（查找 session 放入上下文 在请求处理过程中使用上下文 清空上下文）

  至于 logout 函数就是失效一下 session 即可

- 然后我们创建 TimerService 来计时 实现很简单 详见 Ebook 仓库代码

- 问题的解答：
  在 Controller 和 Service 层都使用了 session 作用域的 scope。
  - Service 层使用 session 的原因：
    - 用户会话保持的时间是一个状态 需要有状态的服务 使用默认的单例的话 每个用户获取到的 service 都是同一个实例 无法为每一个用户维护不同的状态 所以显然不用单例模式 同理的 如果选用 prototype 同一个用户每一次调用会获取到不同的服务 每次都会获得一个新的计时器 自然也不符合要求
    - 而既然要求一个会话维护一个状态 那么 session 作用域是最好的选择 即一个用户如果有新的会话 调用的 service 就会新创建一个实例 做到一次会话对应一个计时器对应一个状态 实现为每一次会话记录持续时间
  - Controller 层使用 session 的原因：
    - 如果服务层使用了 session 作用域 而控制层却使用单例作用域 因为控制层只被创造一次 也就只进行一次依赖注入 也就是说控制层实际上只会调用同一个服务层实例 那么服务层的 session 作用域也就无效了 同理如果是 prototype 作用域 会出现多个 controller 实例注入了同一个服务层实例的问题 而且也没必要每次请求都创建新的控制层实例 所以也不妥
    - 和服务层一样使用 session 作用域是最好的选择 同一个会话的所有请求对应控制层 这个控制层又会对应注入一个服务层

## 9.25

### 异步通信模型

- 为什么需要异步模型（而不用同步模型）：

  1. 上层和接口还是紧耦合的
  2. 缺少调用保障
  3. 软件声明
  4. 没有请求的 buffer
  5. 过于强调请求响应模型
  6. 交流是不可靠的
  7. 通俗理解：同步模型下如果有超过服务器处理能力的高并发请求 所有超过阈值的请求都会被抛弃 而异步模型就可以塞入消息队列慢慢处理 直接响应用户 告知请求一定会被处理

     如果请求数始终超过服务器能力 那么同步异步没有区别 都无法处理 只能提升资源

- 什么是异步模型：没有服务端和客户端之分 而是用消息中间件来处理异步信息 就好比你给室友发条 wx 叫他买早饭 你只需要发送出消息 不需要等待响应而阻塞 也不需要知道室友买早饭的过程

- kafka 中有生产者和消费者 生产者（比如控制层）把消息放入类似缓冲区的 topic 区中 等待消费者（比如服务层）取出进行处理

- 客户端如何知道异步处理的结果？

  1. ajax 重新发一个请求确认
  2. websocket 推送
  3. 消费者完成任务后 把结果放入 topic 等待原来的生产者取出进行处理

- java 提供一个 JMS 来进行消息处理 是异步且可靠的（一定会保障消息传输到）

- JMS 消息的格式：

  1. 一个消息头
     - 发送目标
     - 发送模式
     - 消息 ID
     - 发送时间戳
     - 相关消息 ID
     - 回复给谁
     - 有无转发
     - 消息类型
     - 过期时间
     - 优先级
  2. 消息属性（可选 可以作为消息头的自定义扩展）
     - 用户 ID
     - AppID
     - 转发数
     - 组 ID
     - 生产者和消费者的事务 ID
     - 接受的时间戳
     - 消息状态
  3. 消息体（可选）
     - Text：一个 String 对象
     - Map：一个键值对集合
     - Bytes：一个字节数组
     - Stream：一个流对象
     - Object：一个可序列化的对象
     - Message：上述五个消息类的父类

- 如何实现（JMS）

  1. 消息发布有两种类型 点对点和广播 一个通过 queue 一个通过 topic
  2. 向连接工厂获取一个连接 创建一个上下文和 JMS 服务器进行交互
  3. 通过上下文创建消息 进行发送和接受 发送时可以设置上述的 selector 接收异步的消息则需要创建一个 listener 来进行监听 在 onMessage 函数里编写处理操作
  4. 持久化订阅：创建一个持久化的消费者 订阅一个 topic 会把
     所有未过期且未收到的消息接收
  5. 消息浏览器：只浏览消息 不消费
  6. 对于下订单 也就是控制层向某一个 topic 发送订单信息 服务层监听这个 topic 并消费每个订单消息

### Apache Kafka

- kafka 基于日志来存储消息 是只追加的数据 即使用时间戳来标记删除和更新 写的操作速度快

- 由于 topic 的消息是在内存中存储的 每个用户会维护一个目前读到的消息在内存中的偏移量 来保证每个用户读消息不会乱

- topic 很大时可以用哈希分区 甚至可以形成集群 部署到不同服务器上 为了容灾还可以加复制因子参数 来进行备份

### 作业：使用 Kafka 中间件处理订单请求

- 配置 kafka 环境：使用容器即可 新版 kafka 无需再使用 zookeeper 只需要使用内置的 raft 即可 总共两行代码搞定 `docker pull apache/kafka:3.7.0` `docker run -d -p 9092:9092 apache/kafka:3.7.0`
- 在 Spring 里使用 kafka(可参考：https://blog.csdn.net/Eternal_Blue/article/details/125293622)
  1. 首先添加依赖`spring-kafka` 然后在 application.yml 文件里配置 bootstrap-servers（服务 url）
  2. 创建话题：随便创建个类 或者在启动类里 注册类型为 NewTopic 的 Bean spring 会自动读取并在 kafka 里进行创建 参数分别是 topic 名称、分区数和复制因子
  3. 发送消息：以下订单为例 在控制层先进行鉴权获取 uid（因为消息接受时上下文就没有了） 然后调用 kafkaTemplate 的 send 方法发送封装好的消息即可
  4. 监听消息：创建一个 Listener 类 在里面编写函数并打上`@KafkaListener`注解 这个函数会创建一个消费者实例进行消息的监听 注解参数有很多 主要是 topic 名称和 groupId 我的理解 一个组就是多个消费者并发的消费队列中的消息 可以提高效率 如果消息只有 1 个 那就会随机发给组内某一个消费者
  5. 完成操作：消费者接收到下订单的消息后 调用服务层的方法来处理订单 把订单处理的结果使用 websocket 进行推送 即可让用户知道结果了

## 9.30

### WebSocket

- ws 是一个全双工的应用协议 即双向工作对等 底层是 TCP 协议

- ws 应用会运行一个 endpoint 注册此 endpoint 的 uri 作为连接端点
- 连接建立包含两部分 握手和数据传输 使用 GET 向 endpoint 进行请求 会进行协议的升级 握手后协议升级为 ws

- 使用注解@ServerEndpoint 来注册一个 endpoint 作为服务端 OnOpen 函数中进行连接建立时的操作 OnMessage 函数进行收到消息时的操作 OnError、OnClose 同理

- 群发消息如果使用遍历是很慢的 因此需要把 sessionMap 开成并发安全结构 后续可以多线程处理

- ws 支持自定义编码器 对于文本和二进制消息有两个接口 实现接口中的 encode 方法后即可自定义如何编码 同样也有解码器接口

- 通过编写 Message 类的子类 可以实现多种自定义消息类 在 decode 时就可以根据类别对应处理 多个 endpoint 就可以使用一个 decoder （也就是说 比如一个聊天室的 endpoint 一个点赞消息通知的 endpoint 聊天室可以有两种消息 Text 和 Image 点赞可以有一种消息 LikeM 三种消息都编码成文本 在同一个 decoder 里解码 分别解成三种子消息 然后根据消息类型分别处理）

- 对于下订单服务 当 listener 收到订单处理完成的消息时 应该把消息封装后通过注入的 ws 发送给对应用户 用户在前端需要先注册好 ws 服务 可以再下订单之前建立连接 收到 ws 消息后关闭连接

- 总结
  - ajax 实现的是前端的异步处理 即用户点击发送请求后可以立即进行其他操作 收到响应后会自动处理
  - 消息队列实现的是后端的异步处理 让服务的处理可以异步实现 由于异步无法使用响应让用户知道结果 就使用 ws 来实时通知用户

### 作业：使用 WebSocket 实现订单处理通知

- 作业要求：在下订单服务中加入 WebSocket 通知功能 当订单处理完成后 通过 WebSocket 通知用户订单处理结果
- 实现思路：配置一个 WebSocket 服务端点 当 listener 监听到订单处理完成的消息时 调用 ws 服务的发送函数 发送消息给用户 前端页面需要先建立连接 然后监听消息即可
- 前端在何时建立连接：为了不浪费资源 可以在用户进入购物车页面时建立连接 在用户离开购物车页面时关闭连接

- 代码实现：在后端配置一个 websocket 的端点 这个端点不会收到消息 只需要封装一个 sendToUser 函数用于给前端的用户推送消息即可 sessionMap 采用 uid 做键

  实现端点后 在 finishOrder 的监听器中向用户发送消息 如果处理成功 发送“订单成功处理” 否则发送“订单处理失败+{异常信息}”

  前端在购物车页面加入 ws 使得进入购物车页面后与后端端点建立连接 关闭页面后关闭连接 避免不必要的资源浪费 为 onmessage 方法配置一个简单的 alert 用户将会在收到消息时看到一个提醒框

## 10.9

### Transaction

- 基本概念

  - 事务是一组操作的集合 保证这组操作要么全部成功 要么全部失败
  - 事务的四个特性：ACID

    - Atomicity：原子性 事务要么全部成功 要么全部失败
    - Consistency：一致性 事务前后数据的完整性保持一致
    - Isolation：隔离性 事务之间互不干扰
    - Durability：持久性 事务一旦提交 数据就会永久保存

- JTA 是 Java 提供的事务管理接口 使用@TransactionAttribute 注解来控制事务的传播属性

  - REQUIRED：（默认）如果当前线程有事务就加入 如果没有就新建一个事务
  - REQUIRES_NEW：无论如何都新建一个事务 这种属性可以让子方法的失败不影响父方法的事务
  - SUPPORTS：如果有事务就加入 如果没有就不用事务
  - NOT_SUPPORTED：不支持事务 遇到事务后挂起 当前方法执行完后再恢复
  - MANDATORY：必须有事务 如果没有事务就抛出异常
  - NEVER：不能有事务 如果有事务就抛出异常
  - Spring 中此注解变为@Transactional(propagation = Propagation.REQUIRED)

- 事务的隔离

  - 未隔离的事务可能会出现以下问题

    - 脏读：事务 A 进行写入 写入过程中事务 B 读取到了未提交的数据 事务 A 后续进行了回滚 此时事务 B 读取到的数据就是不一致的
    - 不可重复读：事务 A 读取第一次数据 之后事务 B 进行了写入 事务 A 再次读取数据时发现数据不一致
    - 脏写：事务 A 进行写入 事务 B 也进行了写入 导致数据不一致
    - 幻读：事务 A 需要查询满足某些条件的数据 在查询一次后 事务 B 插入了一条新的符合条件的数据 导致事务 A 再次查询时发现数据增加了新的“幻影”数据行

  - 使用@Transactional 的 isolation 属性来设置隔离级别（从上到下隔离级别逐渐增高 常用可重复读）
    - READ_UNCOMMITTED：允许读取未提交的数据 会出现脏读、不可重复读、幻读
    - READ_COMMITTED：只能读取已提交的数据 避免了脏读 但是会出现不可重复读、幻读
    - REPEATABLE_READ：确保同一事务内多次读取同一行数据是一致的 避免了脏读、不可重复读 但是会出现幻读
    - SERIALIZABLE：事务完全串行化 避免了脏读、不可重复读、幻读 但是性能较差

- 多数据库的写入

  - 当存在多个数据源时 Tomcat 会自动使用分布式的事务 采用**两阶段提交** 第一阶段向所有数据库询问是否准备好 第二阶段若所有数据库都准备好则提交 否则回滚 此种处理仍会出现错误 但是概率较低 可以人工处理

- 锁机制

  - 乐观离线锁：数据会被用户 session 读取后离线编辑 在写入更新数据时先查询数据的版本号 然后在更新时判断版本号是否一致 如果不一致说明基于旧数据进行了修改 则不进行更新 否则更新数据 并将版本号+1 适用于写远少于读的场景
  - 悲观离线锁：加上写锁 保证只有一个线程可以写入数据 适用于写入操作频繁的场景
  - Coarse-Grained Lock：粗粒度锁 一次锁住多张关联的表
    - 乐观锁：给关联的对象加上共享的版本号（可以是内存也可以持久化） 如果对象的版本号被修改 其关联的对象将不能写入
    - 悲观锁：给版本号上锁 保证只有一个线程可以写入

- 注：@Transactional 注解只能对于资源管理器（比如数据库 消息队列）事务有效 对于非资源管理器事务（比如局部变量 x++）无效

### 作业：在下订单的服务中加入事务管理

- 作业要求：在保存订单的 saveOrder 方法与保存订单项的 saveOrderItem 方法中加入事务管理 使得两个保存方法要么同时成功 要么同时失败
- 实现比较简单 在 saveOrder 和 saveOrderItem 方法上加上@Transactional 注解即可 两个方法都会在父方法的事务中运行
- 显然不能使用 REQUIRES_NEW 因为这样会新建一个事务 导致回滚时只会回滚子事务 而不会回滚其他事务

## 10.16
 
### 事务管理

- 事物的回滚和提交实际上是资源管理器通过redo log、undo log来实现的 

- 可串行化调度
  - 调度：并发事务的执行顺序
  - 串行调度：事务完全按照顺序执行
  - 并发调度：事务可以并发执行
  - 可串行化调度：并发执行的事务的结果和串行执行的结果等价 则称这个并发调度是可串行化的 可串行化调度太多 通常只找子集
  - 等价交换：两个事务交换位置后结果不变 比如交换两个读、交换两个不同数据的读写
  - 冲突可串行化调度：通过等价交换把一个并发调度转化为串行调度 即可证明这个并发调度是可串行化的
  - 无冲突的调度可以使用等价交换转换为串行调度 有冲突的调度则需要使用冲突图来判断是否可串行化
  - 冲突图：事务之间的冲突关系 用图表示 有向边表示冲突 无环则可串行化

- 事务提交和回滚
  - 数据库恢复机制：无非是单机多副本、主从复制、异地多机灾备等
  - 策略
    - 原子性
      - 窃取：未结束事务可以将脏页落盘 占用内存少 但是影响原子性 需要undo log
      - 非窃取：未结束事务不能将脏页落盘 不影响原子性 占用内存多
    - 持久性
      - 强制：已完成事务必须落盘 不存在持久性问题 但是IO开销大
      - 非强制：已完成事务可以不落盘 但是可能会丢失数据 需要redo log
  - 日志
    - redo用于持久性 undo用于原子性
    - 日志是磁盘文件 但是由于写入日志是不修改的 可以顺序写入 速度很快 比数据库的写入快很多
    - 日志记录了每一次数据库的操作 包括事务的开始和结束范围等
    - 按功能分类
      - Undo Log：格式为<事务ID，数据项，数据旧值> 用于回滚 在数据库写入之前写日志 一般还包含一个日志序号LSN（Log Sequence Number）用于记录日志的顺序 可以是逻辑日志或物理逻辑日志
      - Redo Log：格式为<事务ID，数据项，数据新值> 用于重做 必须是物理日志
    - 按性质分类
      - 逻辑日志：记录事务中高层抽象的逻辑操作 相当于SQL语句 比如小明的账户减少了100元 不是幂等的 不能重复执行
      - 物理日志：记录数据库的具体物理操作 比如某个页面的某个offset的数据由A改为B 是幂等的 可以重复执行
      - 物理逻辑日志：记录数据页面的物理信息 但是记录的是逻辑操作
    - 日志的性质
      - 幂等性：重复执行不会产生不同的结果 逻辑日志不满足
      - 失败可重做性：日志执行失败后 可以通过重做达成恢复 逻辑日志不满足
      - 操作可逆性：逆向执行日志可以撤销操作 物理日志不满足
    
## 10.21