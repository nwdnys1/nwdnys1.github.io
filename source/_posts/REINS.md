---
title: 在SJTU-REINS的打工日记
date: 2024-10-05 21:19:00
categories: 实验室
tags:
  - 打工
index_img:
banner_img:
excerpt: "大三开学顺利和 chp 面谈并进组开始打工 这个博客用来记录一下每一份工作项目的经历和经验"
---

大三开学顺利和 chp 面谈并进组开始打工 这个博客用来记录一下每一份工作项目的经历和经验

# LIGHTHOUSE

灯塔项目是一个类似于海上管理船只位置的云系统的项目 只不过空间由海域变为上海市区 对象由船只变为无人机等移动物联网设备

简单来说 灯塔系统会收集处于三维空间内各个个体的数据 并存储在一个云边融合系统（CEDS）内 之后将数据整理封装为态势数据 将态势数据分发回给每个个体 让个体通过实时的态势数据进行任务的规划和调度 态势数据会分为两部分 一部分是以个体为中心 在单位时间内可以安全独占的空间范围 另一部分是以个体为中心 依据任务需要而划分的一块空间范围内所有其它个体的数据

我负责的部分主要是从已有的 CEDS 系统中提取需要的数据 并封装为合适格式的态势数据进行分发 比较简单

## CEDS

CEDS 是黄子昂学长的硕士毕业论文中提出的云边融合存储系统 利用了边缘节点本身少量的数据存储与计算能力以及其分布于移动物联网设备附近的特点 实现了基于数据的就近存储、查询任务的划分下推以及负载感知的数据迁移功能的存储系统 做到了传输带宽的减少以及查询的加速 具体实现可以见其论文 我简单讲一下我的理解

### 边缘数据就近存储机制

大部分云边融合系统会将数据存储于资源富足可扩展的云端数据库中 但这会带来很多不必要的传输开销 利用边缘节点本身的存储能力 可以将数据就近存储 大大减少传输延迟

然而数据的就近存储会带来其他问题 比如原本全都位于云端中心的数据 由于就近存储就会分布在不同的边缘节点上 针对此问题 CEDS 提出一种基于 Rosetta 过滤器的全局索引机制 简单来讲 这个过滤器能够实现一个数据表内任一字段的范围过滤 即给定一个字段的某一范围 在常数时间内返回这个表是否存在这个范围内的数据 基于此种过滤器 加上基于时间划分的数据分表 可以做到在很短的时间内定位到某一个时间范围内的数据分表 并快速判断哪些分表内存在本次范围查询相关的数据 这就是 CEDS 的全局索引机制 基于此种索引 CEDS 在云端仅需存储数据表的元信息摘要（包括过滤器的 bitarray） 同时这也将为后文的查询下推提供便利

### 查询任务拆分下推

大部分云边存储系统基于边缘节点的存储数据 每次查询会将相关的数据表全部聚合到云端后进行筛选 产生了很多不必要的传输开销 CEDS 基于任务划分 将查询和聚合任务下推给各个相关的边缘子节点 减少带宽开销

具体而言 一次查询会先向云端中心索要本次查询可能涉及到的所有数据分表 以及这些分表存储在哪些边缘节点上 其方法可以简单的由之前提到的过滤器实现

获取到节点列表后 只需要把子查询任务分发给这些节点即可 每个子节点会进行相关的范围查询（节点内存在常规的索引来加快查询）并把查询结果返回 最终在查询节点进行数据聚合任务 把结果返回给用户

### 负载感知数据迁移

数据就近存储定会存在不均衡现象 由于查询任务划分给子节点并发执行 查询的延迟显然由查询时间最大的子查询决定 如果某些节点上的数据查询次数特别多 导致超出边缘节点的承受范围 导致子查询阻塞 就会导致所有涉及的查询延迟显著变高 为了防止此种情况出现 CEDS 会监测并记录每段时间内边缘节点的查询资源开销 比如记录前 3 分钟内某一节点的内存占用 一旦超过 1G 就判定存在热点数据 并将热点数据迁移到云端来减缓此节点的压力

此种策略是折中的策略 理论上可以达到最均衡的方案肯定是为每一个边缘节点根据查询开销动态分配性能资源 但这在现实中肯定不可行 因此使用较为折中的策略来解决数据不均衡分布的问题

### 部署

跟随仓库中的指导 在自己的电脑上部署一下 CEDS

1. 用 IDEA 跑起中心节点 需连接本地的 MySQL 和 MongoDB 服务
2. 用容器部署 12 个 MongoDB 作为边缘节点的数据库 再用容器部署 12 个边缘节点（基于 python） 手动在本地运行一个 center 节点用于查询 会监听 8000 端口
3. 本地运行 parse_csv 解析数据集 load_data 将数据导入边缘节点 最后用 register 接口把固定的元数据上传到数据中心
4. 运行各个查询进行试验即可

## 工作内容

### 思路

我的任务很简单 只需要进行查询后封装为相应格式的态势数据即可 即学会如何查询与如何使用正确的函数进行封装

### 如何查询所需数据

- 首先需要注册元信息 告诉数据中心这个元数据组的字段都是什么样的

  CEDS 提供了注册接口`/metaData/register` 请求体形如下：

  ```
  {
        "id": "6701140529b28d4cd90959d0",
        "topicPrefix": "taxi",
        "collectionName": "taxi",
        "payloadType": "json",
        "timeField": "TIMESTAMP",
        "fields": {
            "TAXI_ID": {"name": "TAXI_ID", "type": "str"},
            "TRIP_ID": {"name": "TRIP_ID", "type": "str"},
            "LONGITUDE": {
                "name": "LONGITUDE",
                "type": "float",
                "min": "-180",
                "max": "180",
                "granularity": "0.001",
            },
            "SPEED": {
                "name": "SPEED",
                "type": "float",
                "min": "0",
                "max": "120",
                "granularity": "1",
            },
            "LATITUDE": {
                "name": "LATITUDE",
                "type": "float",
                "min": "-180",
                "max": "180",
                "granularity": "0.001",
            },
        },
  }
  ```

  后续我们应该要先定好数据的元信息 然后进行测试

- CEDS 提供了查询接口`/statistic/searchTables`来查询数据相关的分片信息 接口的请求体格式类似如下：

  ```
      {
          "topic": topic,
          "realtime": False,
          "startTime": t_start * 60,
          "endTime": t_end * 60,
          "filters": [
              {"field": "LONGITUDE", "op": "bet", "val1": lon_start, "val2": lon_end},
              {"field": "LATITUDE", "op": "bet", "val1": lat_start, "val2": lat_end},
          ],
      }
  ```

  topic 即资源路径 realtime 我查看了代码 是注释掉的 用不着 startTime 和 endTime 就是时间范围 filter 内是各个字段的范围 比如这里有经度和纬度 经度对应的范围 op 是运算符 目前的实现中字符串只支持 equal 数值只支持 bet

  响应的数据形如下：shards 是数据包含在哪些节点的哪些分表里 比如这里是节点 1 的 05 到 11 分表 parseConfig 就是之前此元数据组注册的摘要

  ```
      {
          "shards": {"node1": [118605, 118606, 118607, 118608, 118609, 118610, 118611]},
          "parseConfig": {
              "id": "6701140529b28d4cd90959d0",
              "topicPrefix": "taxi",
              "collectionName": "taxi",
              "payloadType": "json",
              "timeField": "TIMESTAMP",
              "fields": {
                  "TAXI_ID": {"name": "TAXI_ID", "type": "str"},
                  "TRIP_ID": {"name": "TRIP_ID", "type": "str"},
                  "LONGITUDE": {
                      "name": "LONGITUDE",
                      "type": "float",
                      "min": "-180",
                      "max": "180",
                      "granularity": "0.001",
                  },
                  "SPEED": {
                      "name": "SPEED",
                      "type": "float",
                      "min": "0",
                      "max": "120",
                      "granularity": "1",
                  },
                  "LATITUDE": {
                      "name": "LATITUDE",
                      "type": "float",
                      "min": "-180",
                      "max": "180",
                      "granularity": "0.001",
                  },
              },
          },
      }
  ```

  当你向 8000 端口的查询中心发送请求后 其会先向云端数据中心发送上述请求并得到子节点列表 然后进行查询下推 返回结果

- 向 8000 的查询中心发送请求可以进行查询 这一步就是用户做的了 或者说我要做的 进行查询后封装

  请求体如下：

  ```
  {
    "function": "chadingdan",
    "module": "centerTasks",
    "filter": {
        "topic": "taxi",
        "realtime": False,
        "startTime": 1372662000,
        "endTime": 1372669200,
        "filters": [{"field": "TRIP_ID", "op": "str_eq", "val1": trip_id}],
    },
    "args": {"no": "args"},
  }
  ```

  这个请求会查询出 TRIP_ID 等于某一个值的所有数据 即某一个订单的轨迹数据 可以看到 function 是写死的类型 只针对了 taxi 一种数据组 不方便解耦 以后可以在应用层级上拓展

  论文内还测试了另外两种查询 一个是指定地区内经过的所有车辆 id 一个是时间范围内所有超速 60 的车辆 id 后者没有找到测试代码 不过查询的逻辑应该同理很简单

- 针对态势数据需要的查询 我们可以仔细分析一下：
  1. 第一部分态势数据需要确定一个 robot 在接下来某一段时间内可以安全独占的空间范围 重点是如何计算这个范围 比如查询附近某一小范围的所有 robot 然后根据速度信息进行计算？
  2. 第二部分态势数据需要确定一个 robot 在当前时间某一个大范围内所存在的其他 robot 的数据 重点是如何确定范围以及如何获取最新数据

### 汇报

- 模拟发送数据时发现一个问题 模拟每隔 1s 发送数据 接受到的间隔却会大于 1s
- 原本就有的心跳机制是用于检测采集进程是否可以删除的 就是那个 workers
- 上传数据时更新的索引有问题 解决一下
- 看一下如何下发态势数据
- 看看相关范围如何维护
- 开放一下mysql的端口
- 使用redisearch来进行范围查询

- 目前实现：

  - sender.py: 模拟设备发送数据 读取一个节点的数据 根据 taxi_id 划分为多个 list 然后每个 taxi 起一个线程去连接 mqtt 每隔 1s 发送一次数据
  - realtime_map.py: 维护两个结构 realtime_map 和 online_clients 一个是实时数据 一个是在线设备列表 一个节点运行一个实例去维护这两个结构 收到数据后更新 realtime_map 并更新 online_clients 判断设备离线的标准是每隔 2s 进行检查 如果上一次收到数据的时间距离现在超过 2s 就认为设备离线

    另外写了个 flask 来展示实时数据和在线设备列表 结果就是数据上传完 2s 后会断开连接 以后需要模拟设备转到另一个节点的情况

    由于需要监听的 topic 实际上和 sub 一样 所以需要合并 但是 sub 里的逻辑是每一个 topic 一个线程 而这里是一个节点一个线程 所以需要修改一下

  - client_track.py: 一个节点运行一个实例 用于创建采集线程 sub 监听 online 话题 通过心跳机制维护在线设备列表来判断采集线程是否需要创建或回收 这部分基本没有动逻辑 只修复了一些 bug
  - sub.py: 数据采集进程 一个 topic（也就是一个设备种类）一个线程 用于监听设备发送的数据并存入数据库 更新摘要 上传索引 现在是每 3s 存一次数据 每 6s 上传一次索引 索引部分没有动 不知道是否有用 未来需要实时存储数据的话（比如导航） 就存到 redis 里让其他模块去取

### 10.11 组会

- 强化学习进行独占空间的计算 需要输入哪些数据 目前看来需要与人的距离以及实时速度、加速度
- 态势数据累计到一定程度后 使用这些数据进行空间使用效能的分析 并根据这些分析找到可以提升效能的点 比如算法的改进 或是空间资源的调度
- 态势数据统一格式 设备的上传数据也需要屏蔽差异性

### 10.18 组会

- 元数据更新有 6s 的延迟 因此需要额外的信息来找到实时位置 大致思路是设备经过一个边缘节点时 边缘节点向中心发送进入的时间戳索引 离开时发送离开的时间戳索引 这样就可以通过这两个时间戳知道设备实时位于哪个边缘节点中 索引形如<设备 ID, 边缘节点 ID, 进入时间戳, 离开时间戳> 通过这个索引可以找到设备在哪个边缘节点中的数据分表 可以通过 kafka 的连接和断开事件来触发这个索引的发送

### 10.23 组会

- 组会上我的核心思路概括一下就是：由于态势数据的计算只需要实时数据 因此不适合向数据库里查询获取 因为数据库里存储的绝大部分都是历史数据 查询时连带着这些没有必要的数据会导致很多额外的开销 CEDS 提供的接口更适合用于历史数据的分析 比如示例中的查询一个时间段内哪些车超速了 或者是某一辆车的轨迹数据 不妨把实时数据维护在内存里 查询快 占用的资源也不会太多

  先假设节点的管辖范围（就是进入这个范围 设备就会连接到这个节点）是正方形 每个节点的管辖范围会紧密连接 节点的相关范围则是比管辖范围略大一圈的正方形 会与相邻 8 个节点的管辖范围相交 相关范围的维护是为了解决一个设备在两个节点的交界处时不好通信的问题

  设备通过 kafka 向边缘节点实时发送数据 边缘节点在内存里维护两个 map 其结构形如<设备 ID, 设备最新数据> realtimeMap 是边缘节点管辖范围内所有设备的最新数据 nearMap 是边缘节点相关范围内但不在管辖范围内的设备最新数据 边缘节点在接受到设备的每一条数据后 都将数据插入 realtimeMap 中 同时计算一下这条数据的位置是否位于邻近 8 个节点的管辖范围内 如果是 就向这个节点发送这条数据 以便维护 nearMap （因为都是矩形 计算是否属于管辖范围应该比较简单）

  对于此边缘节点 每隔 1s 会计算管辖范围内所有设备的态势数据 节点取出此时内存中的两个 map 合并 得到一个大 map 这个大 map 就包含了计算所需要用到的所有实时数据 计算完每一个设备的态势数据后 再根据设备 id 找到对应连接 分发给对应设备 如果找不到某个设备 A 的连接 说明它已经离开管辖范围 把这些态势数据向附近节点进行广播 附近节点得到态势数据后 查找自己的 kafka 节点连接中是否存在设备 A 的连接 如果不存在就抛弃数据 如果存在就把态势数据下发给设备 A （还有一种解决方法是 查询当前的 nearMap 确定设备 A 的位置 根据这个位置找到 A 位于哪一个节点 把态势数据发送给这个节点 但是我觉得会存在延迟问题 可能要发送态势数据时 这个节点还未更新 A 的实时位置 导致 A 还位于这个节点中）

  整个过程似乎不需要和中心进行任何连接 只利用了边缘节点的资源 中心节点的作用可能仅当需要查询历史数据时用到 并且每一个节点都只和邻近的节点以及管辖范围内设备进行通信 延迟很低 也降低了带宽开销

### 10.30 组会

- 索引还是应该定期存储到数据库里 
- 把设备扫描到八分树划分的空间里 形成一个节点集来表示这个设备的形状 去八分树里扫描 来判断哪些空间是有多个设备冲突的
- 下发的态势数据的另一部分 需要把某个范围（可以让设备自己定 比如100m）内的其他设备以及一些静态障碍物的数据下发给设备 只需要位置即可
- 量化每块空间的价值 在真实场景下做实验 证明价值的有效性以及场景的空间利用率确实提高了
- 还要负责通信协议和数据格式的设计 也就是设备上传数据的格式 以及设备如何和边缘节点建立通信 自己的三次握手四次挥手等